{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from influxdb import DataFrameClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = open('auth/influxa.txt','r').read()\n",
    "host='influxdb'\n",
    "port=8086\n",
    "dbname='base'\n",
    "dbname_long='long'\n",
    "protocol = 'line' #'json'\n",
    "client = DataFrameClient(host, port, user, password, dbname)\n",
    "client_long = DataFrameClient(host, port, user, password, dbname_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "if purge:\n",
    "    client.drop_database(dbname)\n",
    "    client.drop_retention_policy(dbname)\n",
    "    client.create_database(dbname)\n",
    "    client.create_retention_policy(dbname, '600d', 1, default=True)\n",
    "    client_long.drop_database(dbname_long)\n",
    "    client_long.drop_retention_policy(dbname_long)\n",
    "    client_long.create_database(dbname_long)\n",
    "    client_long.create_retention_policy(dbname_long, '6000d', 1, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath='../html/'\n",
    "htmlepath_other='//backup-html.myserv.er/' #change to your backup server's (if you have) html path\n",
    "htmlepath='//html.myserv.er/' #change to your server's html path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles={'HU':\"Magyar\",'RO':'RomÃ¢nÄƒ','EN':'English'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtitles={titles[t]:t for t in titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    'Authorization': 'Bearer '+open('auth/grafana.txt','r').read(),\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/folders', headers=headers)\n",
    "folders=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id=[f['id'] for f in folders if f['title']=='COVID-19 Romania'][0]\n",
    "# folder_id=[f['id'] for f in folders if f['title']=='COVID-19 Romania Old'][0]\n",
    "# folder_id=[f['id'] for f in folders if f['title']=='Development'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/search?folderIds='+str(folder_id), headers=headers)\n",
    "dashs=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids={rtitles[d['title']]:d['uid'] for d in dashs if d['title'] in rtitles}\n",
    "iids={rtitles[d['title']]:d['id'] for d in dashs if d['title'] in rtitles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_light={rtitles[d['title'].split(' Light')[0]]:d['uid'] for d in dashs if 'Light' in d['title']}\n",
    "iids_light={rtitles[d['title'].split(' Light')[0]]:d['id'] for d in dashs if 'Light' in d['title']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=['HU','RO','EN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/'+open('auth/sheet.txt','r').read()+'/gviz/tq?tqx=out:csv&sheet='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_szotar():\n",
    "    sheet='szotar'\n",
    "    columns=languages+[i+'_description' for i in languages]+[i+'_source' for i in languages]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[['ID','UI']+columns]\n",
    "    sheet='minidashboard'\n",
    "    df2=pd.read_csv(url+sheet)\n",
    "    df2=df2[['ID','UI']+columns]\n",
    "    df=pd.concat([df,df2])\n",
    "    szotardf=df.set_index('ID')[columns]\n",
    "    szotar=df.set_index('ID').T.to_dict()\n",
    "    szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
    "    szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
    "    szotarEN=df.set_index('EN',drop=False).T.to_dict()\n",
    "    return szotardf,szotar,szotarHU,szotarRO,szotarEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_time_conflicts(series):\n",
    "    ds={}\n",
    "    ts=[]\n",
    "    for d in series:\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        ts.append(t)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(df,measurement,field_columns,tag_columns,shift=False,dbclient=client):\n",
    "    if shift:\n",
    "        df.index+=pd.to_timedelta('12h')\n",
    "    dbclient.query('DROP MEASUREMENT '+measurement)\n",
    "    dbclient.write_points(df, measurement, protocol=protocol,\n",
    "                        field_columns=field_columns,\n",
    "                        tag_columns=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=pd.DataFrame(df[['active','cases','heals','deaths']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance1'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=pd.DataFrame(df[['death','heal','case']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance2'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='countries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:13]].set_index('date')\n",
    "df=df.stack().reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').str.replace('%','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global1'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='global'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=pd.DataFrame(szotardf.stack())\n",
    "ds.columns=['country']\n",
    "ds=ds.reset_index()\n",
    "ds['index2']=ds['ID']+ds['level_1']\n",
    "dc=pd.DataFrame(df.set_index(['DÃ¡tum','tag1','Link'])[languages].stack()).reset_index()\n",
    "dc['index1']=dc['tag1']+dc['level_3']\n",
    "dc=dc.set_index('index1').join(ds.set_index('index2')).set_index('DÃ¡tum')[[0,'country','Link','level_1']]\n",
    "dc.columns=['desc','country','link','lang']\n",
    "dc.index=pd.to_datetime(dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','country','link']\n",
    "tag_columns=['lang']\n",
    "measurement='global2'\n",
    "client.query('DROP MEASUREMENT '+measurement)\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global automatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=['France','Germany','Italy','Romania','Spain','US']\n",
    "columns=['fr','de','it','ro','es','us']\n",
    "eus=['Austria','Belgium','Bulgaria','Croatia','Cyprus', 'Czechia', 'Denmark','Estonia',\n",
    "    'Finland', 'France','Germany','Greece','Hungary','Ireland','Italy','Latvia','Lithuania','Luxembourg',\n",
    "    'Malta','Netherlands','Poland', 'Portugal', 'Romania','Slovakia','Slovenia','Spain','Sweden']\n",
    "eus+=['United Kingdom','Andorra','Armenia','Azerbaijan','Belarus','Bosnia and Herzegovina','Georgia', \n",
    "     'Holy See','Iceland','Liechtenstein', 'Moldova','Montenegro','North Macedonia',\n",
    "       'Norway','Russia','San Marino','Switzerland','Turkey','Ukraine','Kosovo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=[]\n",
    "sheets=['countries_auto_cases','countries_auto_heals','countries_auto_deaths']\n",
    "for i in range(len(sheets)):\n",
    "    sheet=sheets[i]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[[c for c in df.columns if 'Unnamed' not in c]]\n",
    "    ww=pd.DataFrame(df.T[2:].astype(float).sum(axis=1))\n",
    "    ww.columns=['ww']\n",
    "    cn=pd.DataFrame(pd.DataFrame(df[df['Country/Region']=='China']).T[2:].astype(float).sum(axis=1))\n",
    "    cn.columns=['cn']\n",
    "    eu=pd.DataFrame(pd.DataFrame(df[df['Country/Region'].isin(eus)]).T[2:].astype(float).sum(axis=1))\n",
    "    eu.columns=['eu']\n",
    "    df=df[df['Province/State'].astype(str)=='nan']\n",
    "    df=df[df['Country/Region'].isin(countries)]\n",
    "    df=df.set_index(\"Country/Region\").T[1:]\n",
    "    df.columns=columns\n",
    "    dfs.append(df.join(eu).join(cn).join(ww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[0]-dfs[1]-dfs[2]\n",
    "df=df.drop('ro',axis=1)\n",
    "df=df.stack().reset_index()\n",
    "df.columns=['date','type','value']\n",
    "df=df.set_index('date')\n",
    "df['value']=df['value'].astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "df.index=pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global3'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/11/2020\n"
     ]
    }
   ],
   "source": [
    "n=30\n",
    "start=dfs[0][dfs[0]['ro']>30].index.min()\n",
    "print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfs[0].rolling(7).mean().diff()\n",
    "das=[]\n",
    "for c in df:\n",
    "    da=pd.DataFrame(df[c][df[c]>n])\n",
    "    da.index=range(len(da))\n",
    "    das.append(da)\n",
    "das=pd.concat(das,axis=1)\n",
    "das.index=[pd.to_datetime(start)+pd.to_timedelta('1D')*i for i in range(len(das))]\n",
    "df=das.stack().reset_index()\n",
    "df.columns=['date','type','value']\n",
    "df=df.set_index('date')\n",
    "df['value']=df['value'].astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "df.index=pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='global4'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df.set_index('date')[df.columns[10:22]].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_econ'\n",
    "dc=df[[c,'gov_note_econ_tag','law','law_link']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc['date']=resolve_time_conflicts(dc['date'])\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['law']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','law','link','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social1'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_social'\n",
    "dc=df[[c,'gov_note_social_tag','law','law_link']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc['date']=resolve_time_conflicts(dc['date'])\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['law']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','law','link','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social2'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "c='gov_note_fin'\n",
    "dc=df[[c,'fin_tag','fin_link','fin_body']].dropna(subset=[c]).reset_index()\\\n",
    "            .set_index(c).join(szotardf[languages]).reset_index()\n",
    "dc['date']=resolve_time_conflicts(dc['date'])\n",
    "dc=pd.DataFrame(dc.set_index(list(dc.columns[:-3])).stack()).reset_index()\n",
    "dc['index']=dc['fin_body']+dc['level_5']\n",
    "dc=dc.set_index('index')\n",
    "dc.columns=['note','date','tag','link','law','lang','desc']\n",
    "ds=szotardf.stack().reset_index()\n",
    "ds['index']=ds['ID']+ds['level_1']\n",
    "ds=ds.set_index('index')\n",
    "ds.columns=['id','lang2','desc2']\n",
    "dc=dc.join(ds).set_index('date')[['desc','tag','link','lang','desc2']]\n",
    "dc['index']=dc['tag']+dc['lang']\n",
    "ds.columns=['id','lang3','desc3']\n",
    "dc=dc.reset_index().set_index('index').join(ds)\n",
    "dc=dc.set_index('date')[['desc','link','lang','desc2','desc3']]\n",
    "dc['desc']=dc['desc'].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['desc','desc2','link','desc3']\n",
    "tag_columns=['lang']\n",
    "measurement='social3'\n",
    "push2influx(dc,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet='stocks'\n",
    "# df=pd.read_csv(url+sheet)[:-2].drop('Roman allampapir spreadek',axis=1)\n",
    "# sheet='stocks2008'\n",
    "# df2=pd.read_csv(url+sheet)[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dc=pd.DataFrame(df.set_index(['DÃ¡tum']).stack()).reset_index()\n",
    "# dc.columns=['date','stock','value']\n",
    "# dc['year']=2020\n",
    "# dc2=pd.DataFrame(df2.set_index(['DÃ¡tum','DÃ¡tum 2']).stack()).reset_index()\n",
    "# dc2.columns=['date','date2','stock','value']\n",
    "# dc2['year']=2008\n",
    "# dc3=pd.concat([dc,dc2])\n",
    "# dc3=pd.DataFrame(dc3.set_index('stock').join(szotardf).reset_index().set_index(['index','year','date','date2','value']).stack()).reset_index()\n",
    "# dc3=dc3.set_index('date')\n",
    "# dc3.columns=['stock','year','date2','value','lang','langstock']\n",
    "# dc3['value']=dc3['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "# dc3.index=pd.to_datetime(dc3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# field_columns=['value']\n",
    "# tag_columns=['lang','langstock','year','date2','stock']\n",
    "# measurement='stocks1'\n",
    "# push2influx(dc3,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='stocks_all'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks=['S&P 500','DAX','BET','STOXX 600','FTSE 100']\n",
    "stocksv=['SP500 volatilitas','DAX volatilitas','BET volatilitas','Stoxx 600 volatilitas','FTSE 100 volatilitas']\n",
    "stocksa=['WTI','Brent']\n",
    "stocksb=['ROBOR3M']\n",
    "stocksc=['Roman allampapir spreadek','Bid/ask 6 honap','Bid/ask 12 honap ','Bid/ask 3 ev','Bid/ask 5 ev','Bid/ask 10 ev ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "das=[]\n",
    "for stock in stocks+stocksa:\n",
    "    da=df[[stock,list(df.columns)[list(df.columns).index(stock)+1]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stock]\n",
    "    da.index=pd.to_datetime(da.index)\n",
    "    das.append(da)\n",
    "for i,stock in enumerate(stocks):\n",
    "    da=df[[stock,stocksv[i]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stocksv[i]]\n",
    "    da.index=pd.to_datetime(da.index)\n",
    "    das.append(da)\n",
    "das=pd.concat(das,axis=1)\n",
    "for stock in stocksb:\n",
    "    da=df[[stock,list(df.columns)[list(df.columns).index(stock)+1]]].dropna()\n",
    "    da=da.set_index(stock)\n",
    "    da.columns=[stock]\n",
    "    da.index=pd.to_datetime(da.index,dayfirst=True)\n",
    "das=das.join(da)\n",
    "da=df[stocksc].set_index('Roman allampapir spreadek').dropna()*100\n",
    "da.index=pd.to_datetime(da.index,dayfirst=True)\n",
    "das=das.join(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1=das.sort_index(ascending=False)[:'2020-02-26']\n",
    "da2=das.sort_index(ascending=False)[:'2008-09-16'].sort_index(ascending=False).tail(len(da1))\n",
    "da2.index=da1.index\n",
    "\n",
    "dc=pd.DataFrame(da1.stack()).reset_index()\n",
    "dc.columns=['date','stock','value']\n",
    "dc['year']=2020\n",
    "dc2=pd.DataFrame(da2.stack()).reset_index()\n",
    "dc2.columns=['date','stock','value']\n",
    "dc2['year']=2008\n",
    "dc3=pd.concat([dc,dc2])\n",
    "dc3=pd.DataFrame(dc3.set_index('stock').join(szotardf).reset_index().set_index(['index','year','date','value']).stack()).reset_index()\n",
    "dc3=dc3.set_index('date')\n",
    "dc3.columns=['stock','year','value','lang','langstock']\n",
    "dc3['value']=dc3['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "dc3.index=pd.to_datetime(dc3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langstock','year','stock']\n",
    "measurement='stocks1'\n",
    "push2influx(dc3,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='exchangerates'\n",
    "df=pd.read_csv(url+sheet)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=pd.DataFrame(df.set_index(['date']).stack()).reset_index()\n",
    "dc.columns=['date','stock','value']\n",
    "dc=pd.DataFrame(dc.set_index('stock').join(szotardf)\\\n",
    ".reset_index().set_index(['index','date','value']).stack()).reset_index()\n",
    "dc=dc.set_index('date')\n",
    "dc.columns=['stock','value','lang','langstock']\n",
    "dc['value']=dc['value'].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "dc.index=pd.to_datetime(dc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langstock','stock']\n",
    "measurement='stocks2'\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='firms'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dc=df[['Friendly name','Ãœzleti forgalom, 2018 (RON)','Alkalmazottak szÃ¡ma, 2018 (fÅ‘)',\n",
    "       'RÃ©szarÃ¡ny az orszÃ¡gos Ã¼zleti forgalombÃ³l, 2018 (%)','RÃ©szarÃ¡ny az iparÃ¡gi Ã¼zleti forgalombÃ³l, 2018 (%)']]\n",
    "dc.columns=['name','revenue','employees','share','indshare']\n",
    "dc['date']=pd.to_datetime('2020-04-05')\n",
    "dc=dc.set_index('date')\n",
    "dc['employees']=dc['employees'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "dc['revenue']=dc['revenue'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "dc['share']=dc['share'].astype(str).str.replace('%','').astype(float)\n",
    "dc['indshare']=dc['indshare'].astype(str).str.replace('%','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['revenue','employees','share','indshare']\n",
    "tag_columns=['name']\n",
    "measurement='firms1'\n",
    "push2influx(dc,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms2 at page bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2=df[['Friendly name','HigiÃ©nia, tÃ¡volsÃ¡gtartÃ¡s', 'InformÃ¡lÃ¡s', 'AdomÃ¡ny',\n",
    "       'Ãœzleti utak leÃ¡llÃ­tÃ¡sa vagy korlÃ¡tozÃ¡sa',\n",
    "       'Home office, rugalmas munkaidÅ‘', 'RÃ©szleges leÃ¡llÃ¡s', 'Teljes leÃ¡llÃ¡s',\n",
    "       'SzemÃ©lyzet csÃ¶kkentÃ©se (akÃ¡r somai tehnic-el)',\n",
    "       'TÃ¡mogatÃ¡s (pl. telefonos vonal stb.)', 'TesthÅ‘mÃ©rsÃ©klet kÃ¶vetÃ©se',\n",
    "       'EgyÃ©b',\n",
    "       'SÃºlyossÃ¡g (4 = nagyon sÃºlyos, 3 = sÃºlyos, 2 = Ã¡tlagos, 1 = gyenge)']].set_index('Friendly name')\n",
    "dc3=dc.reset_index().set_index('name').join(dc2).reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','higenia',\n",
    "'informalas',\n",
    "'adomany',\n",
    "'uzleti_utak',\n",
    "'home_office',\n",
    "'reszleges_leallas',\n",
    "'teljes_leallas',\n",
    "'szemelyzet_csok',\n",
    "'tamogatas',\n",
    "'testho',\n",
    "'egyebi',\n",
    "'sulyos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=list(dc3.columns[1:])\n",
    "tag_columns=['name']\n",
    "measurement='firms3'\n",
    "push2influx(dc3.fillna(0),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc2=df[['Friendly name','COVID-19 terjedÃ©sÃ©nek megakadÃ¡lyozÃ¡sa','Alkalmazottak egÃ©szsÃ©gÃ©nek vÃ©delme','Ãœgyfelek egÃ©szsÃ©gÃ©nek vÃ©delme','CsÃ¶kkent kereslet','TÃ¡mogatÃ¡s (egÃ©szsÃ©gÃ¼gyi, kapcsolattartÃ¡s)',\n",
    "        'A vÃ¡llalat lÃ©pÃ©seinek indoka(i) HU','A vÃ¡llalat lÃ©pÃ©seinek indoka(i) RO','A vÃ¡llalat lÃ©pÃ©seinek indoka(i) EN',\n",
    "       'SÃºlyossÃ¡g (4 = nagyon sÃºlyos, 3 = sÃºlyos, 2 = Ã¡tlagos, 1 = gyenge)']].set_index('Friendly name')\n",
    "dc3=dc.reset_index().set_index('name').join(dc2).reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'HU','RO','EN',\n",
    "'sulyos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc3=dc3.reset_index().set_index(['date','name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos']).stack().reset_index().set_index('date')\n",
    "dc3.columns=['name','revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos',\n",
    "'lang',\n",
    "'lepesindok']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['revenue','employees','share','indshare','terjedes',\n",
    "'alkegeszseg',\n",
    "'ugyfegeszseg',\n",
    "'csokkereslet',\n",
    "'tamogatasek',\n",
    "'sulyos',\n",
    "'lepesindok']\n",
    "tag_columns=['name','lang']\n",
    "measurement='firms4'\n",
    "push2influx(dc3.fillna(0),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='minidashboard'\n",
    "dm=pd.read_csv(url+sheet)\n",
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "df['date']=pd.to_datetime(df['date'])\n",
    "df=df[df.columns[:10]].set_index('date')\n",
    "for i in dm.set_index('ID')['UI'].iteritems():\n",
    "    df[i[0]]=i[1]\n",
    "sheet='employmentdata'\n",
    "de=pd.read_csv(url+sheet)\n",
    "de['date']=pd.to_datetime(de['date'])\n",
    "de=de[de.columns[:3]].set_index('date')\n",
    "de.columns=['felbontott','felfuggesztett']\n",
    "df=df.join(de.ffill())\n",
    "sheet='bordercrossings'\n",
    "db=pd.read_csv(url+sheet)\n",
    "db['date']=pd.to_datetime(db['DÃ¡tum'])\n",
    "db=db.set_index('date')[['VÃ¡ltozÃ¡s ']]\n",
    "db.columns=['border']\n",
    "df=df.join(db)\n",
    "for c in df.columns:\n",
    "    df[c]=df[c].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "sheet='exchangerates'\n",
    "dx=pd.read_csv(url+sheet)\n",
    "dx=dx[['date','EUR - RON (megvÃ¡ltozÃ¡s)']][5:-1]\n",
    "dx['date']=pd.to_datetime(dx['date'])\n",
    "dx=dx.set_index('date')\n",
    "dx.columns=['xch']\n",
    "dx['xch']=dx['xch'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dx)\n",
    "df['xch']=df['xch'].ffill()\n",
    "sheet='stocks_all'\n",
    "dk=pd.read_csv(url+sheet)[['BET', 'BET hozam']].dropna()\n",
    "dk['date']=pd.to_datetime(dk['BET'])\n",
    "dk=dk.set_index('date').drop('BET',axis=1)\n",
    "dk.columns=['bet']\n",
    "dk=dk.reindex(df.index)\n",
    "dk['bet']=dk['bet'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dk)\n",
    "df['border']=df['border'].sort_index()\n",
    "df['border']=[df['border'][:i].mean() for i in df['border'].index]\n",
    "sheet='MiniGDP'\n",
    "dg=pd.read_csv(url+sheet)\n",
    "dg1=dg[['Date','GDP (QoQ, SA)']].dropna()\n",
    "dg1.index=[(pd.to_datetime('now')-pd.to_timedelta('1.5D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg1))][::-1]\n",
    "dg2=dg[['Date.1','GDP']].dropna()\n",
    "dg2.index=[(pd.to_datetime('now')-pd.to_timedelta('6D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg2))][::-1]\n",
    "dg=dg1.join(dg2)[['GDP','GDP (QoQ, SA)']].astype(float)\n",
    "dg.columns=['gdp','gdpq']\n",
    "dg.index=pd.to_datetime(dg.index)\n",
    "df=df.join(dg)\n",
    "df=df[:pd.to_datetime('now')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=list(df.columns)\n",
    "tag_columns=[]\n",
    "measurement='governance3'\n",
    "push2influx(df,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darken2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0xfefefe >> 1))[2:]\n",
    "def brighten2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0x7f7f7f << 1))[2:]\n",
    "def adjust_lightness(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return mc.rgb2hex(colorsys.hls_to_rgb(c[0], max(0, min(1, amount * c[1])), c[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa={'status':'bar-chart', 'global':'globe','governance':'gavel','stocks':'line-chart','firms':'car','data':'database',\n",
    "    'industry':'industry','exports':'sign-out','credits':'coffee','others':'ellipsis-h','counties':'street-view','macro':'forward',\n",
    "   'dijak':'trophy'}\n",
    "ids={8:'logo',90:'flogo', 10:'title',6:'main_content',12:'status', 19:'global', 18:'governance', 17:'stocks', 16:'firms', 15:'industry', \n",
    "     14:'counties',13:'footer',57:'footer2',23:'lang',66:'credits',82:'report',85:'others',93:'update',94:'data',98:'macro',\n",
    "    106:'dijak'}\n",
    "plots={21:'governance_plot1',24:'governance_plot2',22:'global_plot1',32:'social_plot1',37:'social_plot3',36:'social_plot5',\n",
    "      55:'stock',54:'none',42:'stock_plot3',56:'stock_plot4',41:'stock',43:'stock',44:'stock',46:'stock',45:'stock',\n",
    "      48:'stock',49:'stock',50:'stock',51:'stock',53:'stock',61:'firms3',63:'firms5',96:'stock_plot5',95:'stock_plot6',\n",
    "      100:'macro_scatter'}\n",
    "singlestats={68:'status_plot1',69:'status_plot2',70:'status_plot3',71:'status_plot4',72:'status_plot5',73:'status_plot6',74:'status_plot7',\n",
    "            75:'status_plot14',76:'status_plot9',77:'status_plot10',78:'status_plot11',79:'status_plot12',80:'status_plot13',88:'status_plot10',89:'matrix',\n",
    "            91:'megyecase',99:'GDP growth vs. market and DFM estimates',104:'macro_table'}\n",
    "heatmaps={59:'firms1',60:'firms2'}\n",
    "tables={31:'global_plot2',33:'social_plot2',39:'social_plot4',38:'social_plot6',62:'firms4',64:'firms6',65:'firms7'}\n",
    "tooltips=[64,65]\n",
    "legends={64:86,65:87}\n",
    "legendtext={legends[i]:'' for i in tooltips}\n",
    "strftimes={'HU':'%Y.%m.%d','RO':'%d/%m/%Y','EN':'%Y-%m-%d'}\n",
    "themes={'dark':{'HU':'SÃ¶tÃ©t kinÃ©zet','RO':'TemÄƒ Ã®nchisÄƒ','EN':'Dark theme'},'light':{'HU':'VilÃ¡gos kinÃ©zet','RO':'TemÄƒ deschisÄƒ','EN':'Light theme'}}\n",
    "interactive={'HU':'teljes kÃ©pernyÅ‘','RO':'ecran complet','EN':'fullscreen'}\n",
    "kep={'HU':'kÃ©p mentÃ©se','RO':'salveazÄƒ imagine','EN':'save image'}\n",
    "save={'HU':'adatok letÃ¶ltÃ©se','RO':'descarcÄƒ datele','EN':'download data'}\n",
    "generate_links=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model,theme):\n",
    "    css=''\n",
    "    texts=[]\n",
    "    for panel in model['panels']:\n",
    "        if 'type' in panel:\n",
    "            panel['description']=''\n",
    "            panel['links']=[]\n",
    "            links=[]\n",
    "            t=''\n",
    "            if theme!='dark':\n",
    "                t='-'+theme+'?theme='+theme\n",
    "            if panel['type']=='text':\n",
    "                texts.append(panel['id'])\n",
    "                if panel['id'] in ids:\n",
    "                    i=ids[panel['id']]\n",
    "                    if i=='logo':\n",
    "                        panel['content']='<a target=\"_blank\" href=\"'+\\\n",
    "                        szotar['logo_link'][lang]+'\"><img id=\"logo\" class=\"logo\" alt=\"'+\\\n",
    "                        szotar['logo_alt'][lang]+'\" src=\"'+htmlepath+\\\n",
    "                        szotar['logo_img'][lang]+'\" style=\"height:70px!important;width:200px!important;\"/></a>'\n",
    "                    elif i=='flogo':\n",
    "                        panel['content']='<a target=\"_blank\" href=\"'+\\\n",
    "                        szotar['flogo_link'][lang]+'\"><img id=\"flogo\" class=\"flogo\" alt=\"'+\\\n",
    "                        szotar['flogo_alt'][lang]+'\" src=\"'+htmlepath+\\\n",
    "                        szotar['flogo_img'][lang]+'\" style=\"height:80px!important;width:330px!important;\"/></a>'\n",
    "                    elif i=='lang':\n",
    "                        panel['content']='<br><div class=\"lang\" style=\"text-align: center; font-size:16px;\">'\n",
    "                        for l in ['RO','HU','EN']:\n",
    "                            panel['content']+='&nbsp;&nbsp;<a target=\"_self\" title=\"'+titles[l]+'\" href=\"/d/'+uids[l]+t+'\">'+l+'</a>'\n",
    "                        panel['content']+='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<i class=\"fa fa-paint-brush\"></i>&nbsp;&nbsp;<a target=\"_self\" title=\"'+themes['dark'][lang]+'\" href=\"/d/'+\\\n",
    "                            uids[lang]+'\"><i class=\"fa fa-circle\"></i></a>'+\\\n",
    "                            '&nbsp;&nbsp;<a target=\"_self\" title=\"'+themes['light'][lang]+'\" href=\"/d/'+uids[lang]+'-light?theme=light\"><i class=\"fa fa-circle-o\"></i></a>'\n",
    "                        panel['content']+='&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a style=\"font-size:20px;\" target=\"_blank\" title=\"Help\" '+\\\n",
    "                        'href=\"https://github.com/denesdata/covid19-romania/wiki\"><i class=\"fa fa-question\"></i></a>'\n",
    "                        panel['content']+='</div>'\n",
    "                    elif i=='title':\n",
    "                        panel['content']='<div style=\"text-align:left;\"><h1>'+str(szotar['title'][lang])+'</h1><h3> '+str(szotar['subtitle'][lang])+'</h3></div>'\n",
    "                    elif i in ['main_content','footer','footer2']:\n",
    "                        panel['content']=str(szotar[i][lang])\n",
    "                    elif i in ['credits','others','data','dijak']:\n",
    "                        panel['content']='<p><h4><i class=\"fa fa-'+fa[i]+'\"></i>&nbsp;&nbsp;'+str(szotar[i][lang])+'</h4><div>'+str(szotar[i+'_content'][lang])+'</div></p>'\n",
    "                    elif i=='report':\n",
    "                        panel['content']='<p><span style=\"font-size:26px;padding-right:10px;color:'+model['panels'][7]['colors'][0]+';\"><b>'+\\\n",
    "                            str(szotar[i]['UI'][1:])+'</b></span><span style=\"font-size:18px;\">'+str(szotar[i][lang])+'</span></p>'\n",
    "                    elif i=='update':\n",
    "                        panel['content']='<div style=\"text-align:right;\"><i class=\"fa fa-clock\"></i>'+str(szotar['update'][lang])+' <b>'+pd.to_datetime('now').strftime(strftimes[lang])+'</b></div>'\n",
    "                    else:\n",
    "                        panel['content']='<p><h2><i class=\"fa fa-'+fa[i]+'\"></i>&nbsp;&nbsp;'+str(szotar[i][lang])+'</h2><div>'+str(szotar[i+'_content'][lang])+'</div></p>'\n",
    "                elif panel['id'] in legendtext:\n",
    "                    panel['content']=legendtext[panel['id']]\n",
    "            elif panel['type']=='graph':\n",
    "                if panel['id'] in plots:\n",
    "                    i=plots[panel['id']]\n",
    "                    if (('stock' in i) or (panel['id']==54)):\n",
    "                        panel['timeFrom']= str(int(szotar['report']['UI'][1:])+1)+'d'\n",
    "                        panel['hideTimeOverride']= True\n",
    "                    if i=='stock':\n",
    "                        if lang in ['HU','RO']:\n",
    "                            description=str(szotarHU[panel['title']][lang+'_description'])\n",
    "                            source=str(szotarHU[panel['title']][lang+'_source']) \n",
    "                            panel['title']=szotarHU[panel['title']][lang]\n",
    "                        else:\n",
    "                            description=str(szotarRO[panel['title']][lang+'_description'])\n",
    "                            source=str(szotarRO[panel['title']][lang+'_source'])     \n",
    "                            panel['title']=szotarRO[panel['title']][lang]  \n",
    "                        if description not in ['nan','XXX']:\n",
    "                            panel['description']=description\n",
    "                        if source not in ['nan','XXX']:\n",
    "                            panel['description']+='  \\nðŸ“Š '+source\n",
    "                    elif i!='none':\n",
    "                        panel['title']=szotar[i][lang]\n",
    "                        description=str(szotar[i][lang+'_description'])\n",
    "                        source=str(szotar[i][lang+'_source'])    \n",
    "                        if description not in ['nan','XXX']:\n",
    "                            panel['description']=description\n",
    "                        if source not in ['nan','XXX']:\n",
    "                            panel['description']+='  \\nðŸ“Š '+source\n",
    "                    for s in panel['seriesOverrides']:\n",
    "                        if s['alias'] not in ['/./']:\n",
    "                            if lang in ['HU','RO']:\n",
    "                                s['alias']=szotarHU[s['alias']][lang]\n",
    "                            else:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "                        if 'fillBelowTo' in s:\n",
    "                            if lang in ['HU','RO']:\n",
    "                                s['fillBelowTo']=szotarHU[s['fillBelowTo']][lang]\n",
    "                            else:\n",
    "                                s['fillBelowTo']=szotarRO[s['fillBelowTo']][lang]\n",
    "                    for s in panel['targets']:\n",
    "                        if lang in ['HU','RO']:\n",
    "                            sz={s:szotarHU[s] for s in szotarHU if szotarHU[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=sz[s['alias']][lang]\n",
    "                        else:\n",
    "                            sz={s:szotarRO[s] for s in szotarRO if szotarRO[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "\n",
    "            elif panel['type'] in ['singlestat','ryantxu-ajax-panel']:\n",
    "                if panel['id'] in singlestats:\n",
    "                    i=singlestats[panel['id']]\n",
    "                    panel['title']=szotar[i][lang]\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\nðŸ“Š '+source\n",
    "            elif panel['type']=='savantly-heatmap-panel':\n",
    "                if panel['id'] in heatmaps:\n",
    "                    i=heatmaps[panel['id']]\n",
    "                    if lang in ['HU','RO']:\n",
    "                        panel['title']=szotarHU[panel['title']][lang]\n",
    "                    else:\n",
    "                        panel['title']=szotarRO[panel['title']][lang]\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\nðŸ“Š '+source  \n",
    "            elif panel['type']=='table-old':\n",
    "                if panel['id'] in tables:\n",
    "                    i=tables[panel['id']]\n",
    "                    panel['title']=szotar[i][lang]\n",
    "                    legend='<table class=\"legend\"><tr><td>&nbsp;</td><td>&nbsp;</td></tr>'\n",
    "                    for s in panel['styles']:\n",
    "                        if lang in ['HU','RO']:\n",
    "                            sz={s:szotarHU[s] for s in szotarHU if szotarHU[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=sz[s['alias']][lang]\n",
    "                        else:\n",
    "                            sz={s:szotarRO[s] for s in szotarRO if szotarRO[s]['UI']=='replace'}\n",
    "                            if s['alias'] in sz:\n",
    "                                s['alias']=szotarRO[s['alias']][lang]\n",
    "                        if panel['id'] in tooltips:\n",
    "                            if 'link' in s:\n",
    "                                if s['link']:\n",
    "                                    s['linkTooltip']=szotar[s['pattern']][lang]\n",
    "                                    legend+='<tr><td>'+s['alias']+'</td><td>'+szotar[s['pattern']][lang]+'</td></tr>'\n",
    "                    if panel['id'] in tooltips:\n",
    "                        legendtext[legends[panel['id']]]=legend\n",
    "                    description=str(szotar[i][lang+'_description'])\n",
    "                    source=str(szotar[i][lang+'_source'])    \n",
    "                    if description not in ['nan','XXX']:\n",
    "                        panel['description']=description\n",
    "                    if source not in ['nan','XXX']:\n",
    "                        panel['description']+='  \\nðŸ“Š '+source\n",
    "            if generate_links:\n",
    "                if panel['type'] in ['graph','ryantxu-ajax-panel','savantly-heatmap-panel']:\n",
    "                    links.append({'targetBlank': True,'title': 'ðŸ•¹ '+interactive[lang],\n",
    "                          'url': '/d/'+uids[lang]+'/?var-lang=$lang&var-theme=$theme&theme=$theme'+\\\n",
    "                                  '&width=900&height=500&tz=Europe%2FBucharest&fullscreen&panelId='+str(panel['id'])+'&${__url_time_range}'})\n",
    "                    links.append({'targetBlank': True,'title': 'ðŸ“· '+kep[lang],\n",
    "                          'url': '/render/d-solo/'+uids[lang]+'/?var-lang=$lang&var-theme=$theme&theme=$theme'+\\\n",
    "                                  '&width=900&height=500&tz=Europe%2FBucharest&panelId='+str(panel['id'])+'&${__url_time_range}'})\n",
    "            panel['links']=links\n",
    "\n",
    "    model['templating']['list'][0]['current']['text']=lang\n",
    "    model['templating']['list'][0]['current']['value']=lang\n",
    "    model['templating']['list'][1]['current']['text']=theme\n",
    "    model['templating']['list'][1]['current']['value']=theme\n",
    "    for option in model['templating']['list'][0]['options']:\n",
    "        option['selected']=False\n",
    "        if option['value']==lang:\n",
    "            option['selected']=True\n",
    "    if theme=='dark':\n",
    "        model['title']=titles[lang]\n",
    "        model['uid']=uids[lang]\n",
    "        model['id']=iids[lang]\n",
    "        open(lang+'.json','w').write(json.dumps(model))\n",
    "    else:\n",
    "        model['title']=titles[lang]+' Light'\n",
    "        model['uid']=uids_light[lang]\n",
    "        model['id']=iids_light[lang]\n",
    "        open(lang+'-light.json','w').write(json.dumps(model))\n",
    "    for text in texts:\n",
    "        css+='\\n#panel-'+str(text)+' .panel-menu-container {display: none !important;}\\n#panel-'+str(text)+' .panel-title-container {cursor: auto !important;}'\n",
    "    open(htmlipath+'/style/grafana/custom.'+theme+'.css','w').write(css)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  if sys.path[0] == '':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dark=json.loads(open('HU.json','r').read().replace(htmlepath_other,htmlepath))\n",
    "\n",
    "# response = requests.get(grafana+'api/dashboards/uid/'+uids['HU'], headers=headers)\n",
    "\n",
    "response = requests.get(grafana+'api/dashboards/uid/hu', headers=headers)\n",
    "model_dark=json.loads(response.content)['dashboard']\n",
    "# model_dark['time']['from']='now-'+str(szotar['report']['UI'][1:])+'d'\n",
    "model_dark['time']['from']='now-'+str((pd.to_datetime('now')-pd.to_datetime('2020-03-13')).days)+'d'\n",
    "model_light=json.dumps(model_dark).replace('dark.css','light.css').replace('lightGray','#52545c')\n",
    "colors_to_darken=['#F2CC0C','#CA95E5','#FF780A','#E0B400','#96D98D','#F2495C','#E02F44',\n",
    "                  'lime','#73BF69','#8AB8FF','#3274D9']\n",
    "for color in colors_to_darken:\n",
    "    model_light=model_light.replace(color,adjust_lightness(color,0.8))\n",
    "model_light=json.loads(model_light)\n",
    "models={'dark':model_dark,'light':model_light}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for panel in model_dark['panels']:\n",
    "#     print(panel['id'],panel['type'],panel['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dark HU\n",
      "<Response [200]> b'{\"id\":4,\"slug\":\"magyar\",\"status\":\"success\",\"uid\":\"hu\",\"url\":\"/d/hu/magyar\",\"version\":15}'\n",
      "dark RO\n",
      "<Response [200]> b'{\"id\":8,\"slug\":\"romana\",\"status\":\"success\",\"uid\":\"ro\",\"url\":\"/d/ro/romana\",\"version\":16}'\n",
      "dark EN\n",
      "<Response [200]> b'{\"id\":6,\"slug\":\"english\",\"status\":\"success\",\"uid\":\"en\",\"url\":\"/d/en/english\",\"version\":12}'\n",
      "light HU\n",
      "<Response [200]> b'{\"id\":5,\"slug\":\"magyar-light\",\"status\":\"success\",\"uid\":\"hu-light\",\"url\":\"/d/hu-light/magyar-light\",\"version\":12}'\n",
      "light RO\n",
      "<Response [200]> b'{\"id\":9,\"slug\":\"romana-light\",\"status\":\"success\",\"uid\":\"ro-light\",\"url\":\"/d/ro-light/romana-light\",\"version\":12}'\n",
      "light EN\n",
      "<Response [200]> b'{\"id\":7,\"slug\":\"english-light\",\"status\":\"success\",\"uid\":\"en-light\",\"url\":\"/d/en-light/english-light\",\"version\":13}'\n"
     ]
    }
   ],
   "source": [
    "for theme in ['dark','light']:\n",
    "    for lang in languages:\n",
    "        print(theme,lang)  \n",
    "        model=get_model(models[theme],theme)\n",
    "        r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                        \"folderId\": folder_id,\n",
    "                                                                        \"overwrite\": True\n",
    "                                                                       })\n",
    "        print(r,r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_annotations(tag, lang):\n",
    "    for iid in [iids, iids_light]:\n",
    "        dash=iid[lang]\n",
    "        if tag=='all':\n",
    "            r=requests.get(grafana+'api/annotations?limit=10000&dashboardId='+\n",
    "                           str(dash), headers=headers)\n",
    "        else:\n",
    "            r=requests.get(grafana+'api/annotations?limit=10000&tags='+tag+\n",
    "                           '&dashboardId='+str(dash), headers=headers)\n",
    "        annotations=json.loads(r.content)\n",
    "        for a in annotations:\n",
    "            r=requests.delete(grafana+'api/annotations/'+str(a['id']), headers=headers)\n",
    "        print(lang,dash,len(annotations),'annotations purged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_annotations(a,lang):\n",
    "    for iid in [iids, iids_light]:\n",
    "        a[\"dashboardId\"]=iid[lang]\n",
    "        requests.post(grafana+'api/annotations', headers=headers, json=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "forras={'HU':'forrÃ¡s','RO':'sursa','EN':'source'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 210 annotations purged\n",
      "HU 5 210 annotations purged\n",
      "RO 8 210 annotations purged\n",
      "RO 9 210 annotations purged\n",
      "EN 6 210 annotations purged\n",
      "EN 7 210 annotations purged\n"
     ]
    }
   ],
   "source": [
    "if purge:\n",
    "    for lang in ['HU','RO','EN']:\n",
    "        purge_annotations('all',lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='global'\n",
    "df=pd.read_csv(url+sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='global'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag,lang)\n",
    "    for i in df.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['tag1'])!='nan':\n",
    "            tags.append(szotar[str(i['tag1'])][lang])\n",
    "        if str(i['tag2'])!='nan':\n",
    "            tags.append(szotar[str(i['tag2'])][lang])\n",
    "        a={\n",
    "          \"panelId\":22,\n",
    "          \"time\":int(pd.to_datetime(i['DÃ¡tum']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['DÃ¡tum'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+i[lang]+'</div><a target=\"_blank\" href=\"'+i['Link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a,lang)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - economic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_econ'])[['gov_note_econ','gov_note_econ_tag','date','law_link']]\n",
    "dc['date']=resolve_time_conflicts(dc['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='economic'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, lang)\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['gov_note_econ_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['gov_note_econ_tag'])][lang])\n",
    "        a={\n",
    "          \"panelId\":32,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_econ']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['law_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a,lang)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_social'])[['gov_note_social','gov_note_social_tag','date','law_link']]\n",
    "dc['date']=resolve_time_conflicts(dc['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='social'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, lang)\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['gov_note_social_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['gov_note_social_tag'])][lang])\n",
    "        a={\n",
    "          \"panelId\":37,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_social']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['law_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a,lang)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance - financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df.dropna(subset=['gov_note_fin'])[['gov_note_fin','fin_tag','date','fin_body','fin_link']]\n",
    "dc['date']=resolve_time_conflicts(dc['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "mtag='financial'\n",
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations(mtag, lang)\n",
    "    for i in dc.T.to_dict().values():\n",
    "        tags=[mtag]\n",
    "        if str(i['fin_body'])!='nan':\n",
    "            tags.append(szotar[str(i['fin_body'])][lang])\n",
    "        if str(i['fin_tag'])!='nan':\n",
    "            tags.append(szotar[str(i['fin_tag'])][lang])\n",
    "        a={\n",
    "          \"panelId\":36,\n",
    "          \"time\":int(pd.to_datetime(i['date']).strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(i['date'])+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div class=\"annotation_\"'+mtag+'>'+szotar[i['gov_note_fin']][lang]+\\\n",
    "            '</div><a target=\"_blank\" href=\"'+i['fin_link']+'\">'+forras[lang]+'</a>',\n",
    "        }\n",
    "        post_annotations(a,lang)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='events'\n",
    "df=pd.read_csv(url+sheet)\n",
    "dc=df[['Friendly name','Date','HU', 'RO','EN','Link', 'Link.1', 'Link.2']]\n",
    "dc.columns=['name','date','HU','RO','EN','link1','link2','link3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='firms'\n",
    "df=pd.read_csv(url+sheet)\n",
    "de=df[['Friendly name', 'RO CAEN sectiune','HU CAEN sectiune', 'EN CAEN sectiune']]\n",
    "de.columns=['name','RO', 'HU','EN']\n",
    "de=de.set_index('name').stack().reset_index()\n",
    "de.columns=['name','lang','industry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc=dc.set_index(['name','date','link1','link2','link3']).stack().reset_index()\n",
    "dc.columns=['name','date','link1','link2','link3','lang','steps']\n",
    "dc=dc.set_index(['name','lang']).join(de.set_index(['name','lang'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "annos1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU 4 0 annotations purged\n",
      "HU 5 0 annotations purged\n",
      "HU\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO 8 0 annotations purged\n",
      "RO 9 0 annotations purged\n",
      "RO\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN 6 0 annotations purged\n",
      "EN 7 0 annotations purged\n",
      "EN\n"
     ]
    }
   ],
   "source": [
    "for lang in ['HU','RO','EN']:\n",
    "    purge_annotations('firms', lang)\n",
    "    purge_annotations('facebook', lang)\n",
    "    dc3=dc[dc['lang']==lang]\n",
    "    ds={}\n",
    "    for i in dc3.T.to_dict().values():\n",
    "        links=''\n",
    "        links1=['']\n",
    "        mtag='firms'\n",
    "        pid=61\n",
    "        atag=szotar['vallalati'][lang]\n",
    "        for link in ['link1','link2','link3']:\n",
    "            l=str(i[link])\n",
    "            if l!='nan':\n",
    "                if links=='':\n",
    "                    links='<a target=\"_blank\" href=\"'+l+'\">'+forras[lang]+'</a>'\n",
    "                    links1[0]=l\n",
    "                    if 'facebook' in l:\n",
    "                        mtag='facebook'\n",
    "                        pid=63\n",
    "                        atag='Facebook'\n",
    "                else:\n",
    "                    links+='; <a target=\"_blank\" href=\"'+l+'\">'+forras[lang]+'</a>'\n",
    "                    links1.append(l)\n",
    "        tags=[mtag]\n",
    "        if str(i['name'])!='nan':\n",
    "            tags.append(str(i['name']))\n",
    "        if str(i['industry'])!='nan':\n",
    "            tags.append(str(i['industry']))\n",
    "        d=str(i['date'])\n",
    "        if d=='nan':\n",
    "            tags.append(str('no date'))\n",
    "            d='2020-03-10'\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        a={\n",
    "          \"panelId\":pid,\n",
    "          \"time\":int(t.strftime(\"%s\"))*1000,\n",
    "          # \"timeEnd\":int((pd.to_datetime(t)+pd.to_timedelta('9h')).strftime(\"%s\"))*1000,\n",
    "          \"tags\":tags,\n",
    "          \"text\":'<div><b>'+str(i['name'])+'</b></div><div class=\"annotation_\"'+mtag+'>'+i['steps']+\\\n",
    "            '</div>'+links,\n",
    "        }\n",
    "        post_annotations(a,lang)\n",
    "        annos1.append({'name':str(i['name']),'date':t,'event':i['steps'],'link':links1[0],'type':atag,'lang':lang})\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push annos to Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "da=pd.DataFrame(annos1).set_index('date')\n",
    "da['event']=da['event'].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "da3=[]\n",
    "for lang in ['HU','RO','EN']:\n",
    "    da2=da[da['lang']==lang].sort_index(ascending=False)\n",
    "    ds={}\n",
    "    ts=[]\n",
    "    for d in da2.index:\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        ts.append(t)\n",
    "    da2.index=ts\n",
    "    da3.append(da2)\n",
    "da3=pd.concat(da3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['name','event','link','type']\n",
    "tag_columns=['lang']\n",
    "measurement='firms2'\n",
    "push2influx(da3,measurement,field_columns,tag_columns,shift=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Industry county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "georo=json.loads(open(htmlipath+'panels/romania-counties.json','r').read())\n",
    "georoco={i['properties']['NAME_1']:i['properties']['ID_1'] for i in georo['objects']['ROU_adm1']['geometries']}   \n",
    "georoco['BucureÈ™ti']=georoco['Bucharest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='industry_county'\n",
    "df=pd.read_csv(url+sheet)[:-2]\n",
    "df=df[df.columns[:4]]\n",
    "df.columns=['HU','RO','EN','value']\n",
    "df['value']=df['value'].str.replace('%','').astype(float)\n",
    "df=df.set_index('RO').join(pd.DataFrame(georoco,index=['county']).T).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'value','county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='counties_current'\n",
    "dg=pd.read_csv(url+sheet, header=None)\n",
    "dgl=dg[[1,4]].set_index(4).T.to_dict()\n",
    "dgl['Dambovita']=dgl['DÃ¢mbovita']\n",
    "dgl['SzucsÃ¡va']=dgl['Suceava']\n",
    "dgl['Galac']=dgl['Galati']\n",
    "dgl['Valcea']=dgl['VÃ¢lcea']\n",
    "dfl=df[languages+['county']].set_index('HU')\n",
    "dh=dfl.join(pd.DataFrame(dgl).T).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=dh[[lang,1,'county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='matrix'\n",
    "df=pd.read_csv(url+sheet)[:-1]\n",
    "df=df[['IND HU short','IND RO short','IND EN short','% of GDP (2018)','GDP gain/loss in 2020 Q2 (%)']]\n",
    "df.columns=['HU','RO','EN','share','q2']\n",
    "df['share']=df['share'].str.replace('%','').astype(float)\n",
    "df['q2']=df['q2'].str.replace('%','').astype(float)\n",
    "df['value']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'share','q2','value']]\n",
    "    dc.columns=['id','x','y','value']\n",
    "    dc['c']=(dc['x']/dc['x'].median())*dc['y']\n",
    "    open(htmlipath+'panels/matrix_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('matrix_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=szotardf[languages].loc[['% of GDP (2018)','GDP gain/loss in 2020 Q2 (%)']].T\n",
    "ds.columns=['x','y']\n",
    "open(htmlipath+'panels/matrix_label.json','w').write(json.dumps(ds.to_dict()))\n",
    "#open('matrix_label.json','w').write(json.dumps(ds.to_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Jake VanderPlas\n",
    "# License: BSD-style\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def discrete_cmap(N, base_cmap=None):\n",
    "    \"\"\"Create an N-bin discrete colormap from the specified input map\"\"\"\n",
    "\n",
    "    # Note that if base_cmap is a string or None, you can simply do\n",
    "    #    return plt.cm.get_cmap(base_cmap, N)\n",
    "    # The following works for string, None, or a colormap instance:\n",
    "\n",
    "    base = plt.cm.get_cmap(base_cmap)\n",
    "    color_list = base(np.linspace(0, 1, N))\n",
    "    cmap_name = base.name + str(N)\n",
    "    return base.from_list(cmap_name, color_list, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "icons={'YoY%':'ðŸ“ˆ', '%':'%', 'proxy index':'âž°', 'value index':'ðŸ’²',\n",
    "       'volume index':'ðŸ›’', 'index':'ã€½'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='EcMonitor'\n",
    "df=pd.read_csv(url+sheet,header=None).dropna(how='all',axis=1).set_index(0)\n",
    "df.index.name='indicator'\n",
    "df.loc['GDP']=df.loc['GDP'].bfill()\n",
    "df.loc['Market consensus']=df.loc['Market consensus'].bfill()\n",
    "df['order']=[100*i for i in range(len(df.index))]\n",
    "df=df.set_index('order',append=True)\n",
    "df=df.drop(['Indicator'],axis=0,level=0)\n",
    "df2=df[1:].drop([1],axis=1)\n",
    "sections=[i[0] for i in df[df.isnull().all(axis=1)].index]\n",
    "df[1]=df[1].fillna('row')\n",
    "df=df[df[1:].dropna(how='all',axis=1).columns]\n",
    "df[1]=df[1].replace(icons)\n",
    "df1=df.stack().dropna().reset_index()\n",
    "df1.columns=['indicator','order','index','value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscaler=1\n",
    "colors=df2.reset_index().set_index('indicator').T.count().to_dict()\n",
    "colors={i:{'size':colors[i]} for i in colors}\n",
    "for i in df2.index:\n",
    "    colors[i[0]]['min']=df2.loc[i[0]].min().min()*cscaler\n",
    "    colors[i[0]]['max']=df2.loc[i[0]].max().max()*cscaler\n",
    "    #colors[i[0]]['min']=df2[df2.columns[1:]].loc[i[0]].min().min()*cscaler\n",
    "    #colors[i[0]]['max']=df2[df2.columns[1:]].loc[i[0]].max().max()*cscaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "colorlist=[]\n",
    "for i in df1[['indicator','value','index']].T.iteritems():\n",
    "    if i[1][2]==2:\n",
    "        if i[1][0] not in ['date']:\n",
    "            ref_color=float(i[1][1])\n",
    "            color='transparent'\n",
    "    elif i[1][2]==1:\n",
    "        color='transparent'\n",
    "    elif i[1][0] in ['date']:\n",
    "        color='transparent'\n",
    "    elif i[1][0] not in colors:\n",
    "        color='transparent'\n",
    "    else:\n",
    "        if i[1][0] in ['GDP','Market consensus','% of information included in the model']:\n",
    "            cmap='Blues'\n",
    "        else:\n",
    "            cmap='RdBu'\n",
    "        rc=(ref_color*1.0-colors[i[1][0]]['min'])*1.0/(colors[i[1][0]]['max']*1.0-colors[i[1][0]]['min']*1.0)\n",
    "        c=(float(i[1][1])*1.0-colors[i[1][0]]['min'])*1.0/(colors[i[1][0]]['max']*1.0-colors[i[1][0]]['min']*1.0)\n",
    "        c=c*0.5/rc\n",
    "        if (i[1][0] in ['Unemployment ratio']):\n",
    "            c=1-c\n",
    "        # color=adjust_lightness(discrete_cmap(colors[i[1][0]]['size'],cmap)(c),1)\n",
    "        color=adjust_lightness(discrete_cmap(20,cmap)(c),1)\n",
    "    colorlist.append(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuelist=[]\n",
    "for i in df1[['indicator','value','index']].T.iteritems():\n",
    "    if i[1][2]==1:\n",
    "        valuelist.append(i[1][1])\n",
    "    elif i[1][0] in colors:\n",
    "        if float(i[1][1])<100:\n",
    "            valuelist.append(str(np.round(float(i[1][1]),1)).replace('.0',''))\n",
    "        else:\n",
    "            valuelist.append(str(int(np.round(float(i[1][1]),0))))\n",
    "    else:\n",
    "        valuelist.append(i[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['color']=colorlist\n",
    "df1['value']=valuelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets={'groups':[],'lang':szotardf.loc[list(df.droplevel('order')[2].index)+['data','desc','type','month']][:].T.to_dict()}\n",
    "sets['lang']={i:{k:sets['lang'][i][k] for k in sets['lang'][i] if str(sets['lang'][i][k]) not in ['nan','XXX']} for i in sets['lang']}\n",
    "for i in df.droplevel('order')[1:][2].iteritems():\n",
    "    if str(i[1])=='nan':\n",
    "        #sets['groups'].append([])\n",
    "        sets['groups'].append([i[0]])\n",
    "    else:\n",
    "        sets['groups'][-1].append(i[0])\n",
    "# sets[0]=[item for sublist in sets['groups'] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_months={'2015-2019':{'HU':'2015-2019','RO':'2015-2019','EN':'2015-2019'},\n",
    "            '2019-06':{'HU':'2019 JÃºn','RO':'2019 Iun','EN':'2019 Jun'},\n",
    "             '2019-07':{'HU':'JÃºl','RO':'Iul','EN':'Jul'},\n",
    "            '2019-08':{'HU':'Aug','RO':'Aug','EN':'Aug'},\n",
    "             '2019-09':{'HU':'Sze','RO':'Sep','EN':'Sep'},\n",
    "             '2019-10':{'HU':'Okt','RO':'Oct','EN':'Oct'},\n",
    "             '2019-11':{'HU':'Nov','RO':'Noi','EN':'Nov'},\n",
    "             '2019-12':{'HU':'Dec','RO':'Dec','EN':'Dec'},\n",
    "             '2020-01':{'HU':'2020 Jan','RO':'2020 Ian','EN':'2020 Jan'},\n",
    "             '2020-02':{'HU':'Feb','RO':'Feb','EN':'Feb'},\n",
    "             '2020-03':{'HU':'MÃ¡r','RO':'Mar','EN':'Mar'},\n",
    "             '2020-04':{'HU':'Ãpr','RO':'Apr','EN':'Apr'},\n",
    "             '2020-05':{'HU':'MÃ¡j','RO':'Mai','EN':'May'},\n",
    "             '2020-06':{'HU':'JÃºn','RO':'Iun','EN':'Jun'},\n",
    "             '2020-07':{'HU':'JÃºl','RO':'Iul','EN':'Jul'},\n",
    "             '2020-08':{'HU':'Aug','RO':'Aug','EN':'Aug'}}\n",
    "sets_months2={\n",
    "            '2019-06':{'HU':'JÃºnius','RO':'Iunie','EN':'June'},\n",
    "             '2019-07':{'HU':'JÃºlius','RO':'Iulie','EN':'July'},\n",
    "            '2019-08':{'HU':'Augusztus','RO':'August','EN':'August'},\n",
    "             '2019-09':{'HU':'Szeptember','RO':'Septembrie','EN':'September'},\n",
    "             '2019-10':{'HU':'OktÃ³ber','RO':'Octombrie','EN':'October'},\n",
    "             '2019-11':{'HU':'November','RO':'Noiembrie','EN':'November'},\n",
    "             '2019-12':{'HU':'December','RO':'Decembrie','EN':'December'},\n",
    "             '2020-01':{'HU':'JanuÃ¡r','RO':'Ianuarie','EN':'January'},\n",
    "             '2020-02':{'HU':'FebruÃ¡r','RO':'Februarie','EN':'February'},\n",
    "             '2020-03':{'HU':'MÃ¡rcius','RO':'Martie','EN':'March'},\n",
    "             '2020-04':{'HU':'Ãprilis','RO':'Aprilie','EN':'April'},\n",
    "             '2020-05':{'HU':'MÃ¡jus','RO':'Mai','EN':'May'},\n",
    "             '2020-06':{'HU':'JÃºnius','RO':'Iunie','EN':'June'},\n",
    "             '2020-07':{'HU':'JÃºlius','RO':'Iulie','EN':'July'},\n",
    "             '2020-08':{'HU':'Augusztus','RO':'August','EN':'August'}}\n",
    "sets_months['type']=szotardf.loc['type'][languages].to_dict()\n",
    "sets['months']={i:sets_months[i] for i in df.loc['date'].values[0]}\n",
    "sets_labels=df[:1].T['date'].to_dict()[0]\n",
    "sets_labels={i:{j:sets_labels[i].split('-')[0]+' '+sets_months2[sets_labels[i]][j] \\\n",
    "    for j in sets_months2[sets_labels[i]]} for i in sets_labels if sets_labels[i] in sets_months2}\n",
    "sets_labels['indicator']=szotardf.loc['indicator'][languages].to_dict()\n",
    "sets_labels[2]={'HU':'2015-2019 Ã¡tlag','RO':'medie 2015-2019','EN':'2015-2019 average'}\n",
    "sets['label']=sets_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19608"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(htmlipath+'panels/macro_sets.json','w').write(json.dumps(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62496"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=df1.join(pd.DataFrame(sets['label']).T,on='index')\n",
    "df4=df3[['value']+languages].T.ffill()\n",
    "for lang in languages:\n",
    "    df3[lang]=df4.T[lang].replace({icons[i]:szotar[i][lang] for i in icons})\n",
    "open(htmlipath+'panels/macro_table.json','w').write(json.dumps(list(df3.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Macro scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='DFMChartYoY'\n",
    "df=pd.read_csv(url+sheet)\n",
    "df=df.set_index('Date').loc[['DFM estimate','GDP','GDP.1','Market consensus','Range68']].T.\\\n",
    "    dropna(how='all',axis=0).astype(float).reset_index()\n",
    "df.index=[(pd.to_datetime('now')-pd.to_timedelta('10H')*(1+i)).strftime('%Y-%m-%d-%H') for i in range(len(df))][::-1]\n",
    "df.index=pd.to_datetime(df.index)\n",
    "df['index']=pd.to_datetime(df['index'].str.replace('-','-20'))\n",
    "df['CI+']=df['DFM estimate']+df['Range68']/2\n",
    "df['CI-']=df['DFM estimate']-df['Range68']/2\n",
    "df['CI++']=df['DFM estimate']+df['Range68']\n",
    "df['CI--']=df['DFM estimate']-df['Range68']\n",
    "df=pd.DataFrame(df.set_index('index').stack()).reset_index()\n",
    "df.columns=['date','type','value']\n",
    "df=df.set_index('date')\n",
    "df['value']=df['value'].astype(float)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "df.index=pd.to_datetime(df.index)+pd.DateOffset(months=1)-pd.DateOffset(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','type','langtype']\n",
    "measurement='macro'\n",
    "push2influx(df,measurement,field_columns,tag_columns,dbclient=client_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}